{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqgtoJhbmWJXsqTkGZc1jK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S7DHZ2xyGjb",
        "outputId": "2c939840-32ee-401f-d526-094b897ebf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "file = open(\"frankenstien-2.txt\").read()"
      ],
      "metadata": {
        "id": "UFeAP_aZyP1s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Standardization\n",
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "metadata": {
        "id": "PUd7ijAHywaR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chars to numbers\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c,i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "7s_7M2yby1hY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if code is working\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"Total Characters: \", input_len)\n",
        "print(\"Total Vocab: \", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFlR268dy4mc",
        "outputId": "9da7941b-722c-47c9-f863-962ecd6f8851"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  18420\n",
            "Total Vocab:  34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data= []"
      ],
      "metadata": {
        "id": "kS0swQBPy638"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through seq\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "  in_seq = processed_inputs[i:i + seq_length]\n",
        "  out_seq = processed_inputs[i + seq_length]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(\"Total Number of Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GERl4zlKy-RZ",
        "outputId": "2add380f-1f8b-495a-f0b6-a9f0aee56620"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Patterns: 18320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting input seq to np array\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "uEn3sQWmzA2A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encoding\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "metadata": {
        "id": "rmU4J8UszDzm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "v5uZmAqazGHc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "j5rbZHf5zJDT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving weight\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "3nOGvbidzMsl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model and let it train\n",
        "model.fit(X,y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF-_qb4yzR_p",
        "outputId": "11c26aa9-9afe-4cf2-e1f9-37a897c9a7b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.9840\n",
            "Epoch 1: loss improved from inf to 2.98402, saving model to model_weights_saved.hdf5\n",
            "72/72 [==============================] - 229s 3s/step - loss: 2.9840\n",
            "Epoch 2/4\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.9250\n",
            "Epoch 2: loss improved from 2.98402 to 2.92499, saving model to model_weights_saved.hdf5\n",
            "72/72 [==============================] - 242s 3s/step - loss: 2.9250\n",
            "Epoch 3/4\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.9165\n",
            "Epoch 3: loss improved from 2.92499 to 2.91647, saving model to model_weights_saved.hdf5\n",
            "72/72 [==============================] - 245s 3s/step - loss: 2.9165\n",
            "Epoch 4/4\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.9120\n",
            "Epoch 4: loss improved from 2.91647 to 2.91202, saving model to model_weights_saved.hdf5\n",
            "72/72 [==============================] - 214s 3s/step - loss: 2.9120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcdda4167a0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recompile model with saved weights\n",
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "XAxC0A0yzUtT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output of the model into characters\n",
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "37TYmTJX0G7Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed to help generate\n",
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwdrVuT0Zeh",
        "outputId": "8f9f1f7f-6090-400e-dca4-d31d0591d060"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" flectionspokedesirefindingfriendthirstintimatesympathyfellowmindeverfallenlotexpressedconvictionmanc \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Genearting the text\n",
        "for i in range(1000): \n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x/float(vocab_len)\n",
        "  prediction = model.predict(x, verbose = 0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as8JPIo00jdu",
        "outputId": "48e3e7de-e7aa-4fdc-eb49-bd0d6d18c8a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
          ]
        }
      ]
    }
  ]
}